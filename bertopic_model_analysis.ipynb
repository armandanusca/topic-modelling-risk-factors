{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from copy import deepcopy\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import swifter\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = '07'\n",
    "end_year = '22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "db = client.frtp\n",
    "collection = db.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the data available\n",
    "result = collection.find({\"year\": {'$lt': start_year, '$gte': end_year}})\n",
    "df = pd.DataFrame(list(result))\n",
    "df['year'] = pd.to_datetime(df['year'], format='%y')\n",
    "df.to_csv(f'collab_dataset_{start_year}_{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop = set([s.replace(\"'\", \"\") for s in stop])\n",
    "\n",
    "    # Add years to prevent spikes\n",
    "    for year in range(1900, 2020):\n",
    "        stop.add(str(year))\n",
    "\n",
    "    # Add small numbers\n",
    "    for num in range(0, 100):\n",
    "        if len(str(num)) < 2:\n",
    "            stop.add(str(num))\n",
    "            num = '0' + str(num)\n",
    "\n",
    "        stop.add(str(num))\n",
    "\n",
    "    # Add these extra stopwords to the list\n",
    "    # TODO: Look through the corpus and decide which are\n",
    "    # extra stopwords needed for this specific domain\n",
    "    extra = [\n",
    "        'use', 'using', 'uses', 'used', 'based', 'including', 'include',\n",
    "        'approach', 'factors', 'business', 'risk','factors16',\n",
    "        'wa', 'ha', 'doe', 'item', '1a', 'factor', '1b', '1aitem', '10-k', \n",
    "        'item','1arisk','factors11','1arisk','factors10k','factorsk13','could',\n",
    "        'factorsk10','may'\n",
    "    ]\n",
    "\n",
    "    for number in range(1,300):\n",
    "      factor_string='factors'+str(number)\n",
    "      stop.add(factor_string)\n",
    "\n",
    "    for word in extra:\n",
    "      stop.add(word)\n",
    "\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].str.lower()\n",
    "df['clean_text'] = df['clean_text'].swifter.apply(lambda x: ' '.join([word for word in text_to_word_sequence(x)]))\n",
    "stop_words = get_stopwords()\n",
    "df['clean_text'] = df['clean_text'].swifter.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df.year.to_list()\n",
    "\n",
    "# Use unclean version of text\n",
    "text = df.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = sentence_model.encode(text, show_progress_bar=True)\n",
    "topic_model = BERTopic(verbose=True,calculate_probabilities=True,language = \"english\",nr_topics=50)\n",
    "topics, probs = topic_model.fit_transform(text,embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a topic\n",
    "topic_model.get_topic(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the topics\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.to_csv('topic_info.csv')\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running DTM on the entire dataset\n",
    "topics_over_time = topic_model.topics_over_time(text, topics, timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10 topics bases on frequency\n",
    "topics_over_time.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time,top_n_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_evolution = pd.DataFrame()\n",
    "timestamps_set = sorted(set(timestamps))\n",
    "for timestamp in timestamps_set:\n",
    "    temp_df = topics_over_time[topics_over_time['Timestamp'] == timestamp]\n",
    "    if topic_evolution.shape[0] == 0:\n",
    "        temp_df = temp_df[['Topic','Name','Words','Frequency']]\n",
    "        temp_df = temp_df.rename(columns={'Frequency':str(timestamp)})\n",
    "        topic_evolution = deepcopy(temp_df)\n",
    "    else:\n",
    "        temp_df = temp_df[['Topic','Frequency']]\n",
    "        temp_df = temp_df.rename(columns={'Frequency':str(timestamp)})\n",
    "        topic_evolution = topic_evolution.merge(temp_df,on='Topic',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_evolution = topic_evolution.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_evolution.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_process = topic_evolution.columns.to_list()\n",
    "columns_to_process.remove('Topic')\n",
    "columns_to_process.remove('Name')\n",
    "columns_to_process.remove('Words')\n",
    "columns_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,len(columns_to_process)-1):\n",
    "    new_column = columns_to_process[index+1].split('-')[0] + '-' + columns_to_process[index].split('-')[0]\n",
    "    topic_evolution[new_column] = topic_evolution[columns_to_process[index+1]] - topic_evolution[columns_to_process[index]]\n",
    "topic_evolution.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics_over_time.Topic.unique()\n",
    "change_in_topics = pd.DataFrame()\n",
    "for topic in topics:\n",
    "    topic_df = topics_over_time[topics_over_time['Topic'] == topic]\n",
    "    topic_df = topic_df.sort_values('Timestamp')\n",
    "    topic_df['Previous_Frequency'] = topic_df.Frequency.shift(1)\n",
    "    topic_df['Change'] = topic_df['Frequency'] - topic_df['Previous_Frequency']\n",
    "    max_freq = max(topic_df['Frequency'])\n",
    "    topic_df['%_Change'] = topic_df['Change']*100/max_freq\n",
    "    change_in_topics = change_in_topics.append(topic_df,ignore_index=True)\n",
    "change_in_topics = change_in_topics[change_in_topics['Topic'] != -1]\n",
    "change_in_topics = change_in_topics.dropna()\n",
    "change_in_topics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(change_in_topics, x=\"Timestamp\", y=\"%_Change\",color='Words', title='YOY change in topic frequency')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
